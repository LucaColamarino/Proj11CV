{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_with_gtFine.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üîß Config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üü¢ Using GPU: {torch.cuda.get_device_name(0)}\") if torch.cuda.is_available() else print(\"üü° Using CPU\")\n",
    "\n",
    "batch_size = 4\n",
    "num_classes = 19\n",
    "epochs = 3\n",
    "resize = (256, 512)\n",
    "checkpoint_path = 'deeplabv3_cityscapes_fine.pth'\n",
    "\n",
    "# üó∫Ô∏è Dataset ufficiale con gtFine\n",
    "class CityscapesFineDataset(Dataset):\n",
    "    def __init__(self, root, split='train', transform=None, resize=(256,512)):\n",
    "        self.img_dir = os.path.join(root, 'leftImg8bit', split)\n",
    "        self.label_dir = os.path.join(root, 'gtFine', split)\n",
    "        self.transform = transform\n",
    "        self.resize = resize\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for city in os.listdir(self.img_dir):\n",
    "            for fn in os.listdir(os.path.join(self.img_dir, city)):\n",
    "                if fn.endswith('_leftImg8bit.png'):\n",
    "                    self.images.append(os.path.join(self.img_dir, city, fn))\n",
    "                    self.labels.append(\n",
    "                        os.path.join(self.label_dir, city,\n",
    "                                     fn.replace('_leftImg8bit.png', '_gtFine_labelTrainIds.png'))\n",
    "                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.images[idx]).convert('RGB')\n",
    "        lbl = Image.open(self.labels[idx])\n",
    "        img = img.resize((self.resize[1], self.resize[0]), Image.BILINEAR)\n",
    "        lbl = lbl.resize((self.resize[1], self.resize[0]), Image.NEAREST)\n",
    "        if self.transform:  \n",
    "            img = self.transform(img)\n",
    "        lbl = torch.from_numpy(np.array(lbl)).long()\n",
    "        return img, lbl\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = CityscapesFineDataset(root='datasets/realcityscapes', split='train', transform=transform, resize=resize)\n",
    "train_ds.images = train_ds.images\n",
    "train_ds.labels = train_ds.labels\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # <= PER ORA DISATTIVA\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False  # <= QUESTO PU√í BLOCCARE SU WINDOWS\n",
    ")\n",
    "\n",
    "\n",
    "# üß† Modello + ottimizzatore + AMP\n",
    "model = deeplabv3_resnet50(pretrained=False, num_classes=num_classes).to(device)\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# üîÅ Checkpoint\n",
    "start_epoch = 0\n",
    "if os.path.exists(checkpoint_path):\n",
    "    ck = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(ck['model'])\n",
    "    optimizer.load_state_dict(ck['optimizer'])\n",
    "    scaler.load_state_dict(ck['scaler'])\n",
    "    start_epoch = ck['epoch'] + 1\n",
    "    print(f\"üîÅ Ripartendo da epoca {start_epoch}\")\n",
    "\n",
    "# üèÅ Training\n",
    "for epoch in range(start_epoch, start_epoch + epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{start_epoch+epochs}\")\n",
    "    for images, masks in loop:\n",
    "        images = images.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "        masks = masks.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(images)['out']\n",
    "            loss = criterion(out, masks)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=running_loss/(loop.n+1))\n",
    "\n",
    "    print(f\"‚úÖ Epoca {epoch+1}: Avg Loss = {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scaler': scaler.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from dataset import COLORS  # Assicurati che COLORS sia un np.array[19, 3]\n",
    "\n",
    "# üîß Config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"{'üü¢' if torch.cuda.is_available() else 'üü°'} Using: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "num_classes = 19\n",
    "model_path = 'deeplabv3_cityscapes_fine.pth'\n",
    "image_path = 'datasets/realcityscapes/leftImg8bit/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png'\n",
    "ground_image_path = 'datasets/realcityscapes/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_color.png'\n",
    "resize = (256, 512)\n",
    "\n",
    "def decode_segmap(pred):\n",
    "    h, w = pred.shape\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for label in range(num_classes):\n",
    "        color_mask[pred == label] = COLORS[label]\n",
    "    return color_mask\n",
    "\n",
    "# üì¶ Load model\n",
    "model = deeplabv3_resnet50(pretrained=False, num_classes=num_classes).to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "\n",
    "# üñºÔ∏è Load and preprocess image\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "ground_image = Image.open(ground_image_path)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(resize),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "# üîç Inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)['out']\n",
    "    output = torch.nn.functional.interpolate(output, size=resize, mode='bilinear', align_corners=False)\n",
    "    prediction = torch.argmax(output.squeeze(), dim=0).cpu().numpy()\n",
    "    seg_image = decode_segmap(prediction)\n",
    "\n",
    "\n",
    "\n",
    "# üìä Visualizzazione\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Predicted Segmentation\")\n",
    "plt.imshow(seg_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Ground Truth Segmentation\")\n",
    "plt.imshow(ground_image)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
