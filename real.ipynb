{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86756fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dataset import COLORS,CityscapesFineDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ Using GPU: NVIDIA GeForce RTX 4070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\colam\\Documents\\GitHub\\Proj11CV\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\colam\\Documents\\GitHub\\Proj11CV\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\colam\\AppData\\Local\\Temp\\ipykernel_30024\\2958784827.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\colam\\AppData\\Local\\Temp\\ipykernel_30024\\2958784827.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Ripreso da epoca 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/29 [Train]:   0%|          | 0/744 [00:00<?, ?it/s]C:\\Users\\colam\\AppData\\Local\\Temp\\ipykernel_30024\\2958784827.py:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 29/29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 744/744 [08:01<00:00,  1.54it/s, loss=0.444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 29: Avg Train Loss = 0.4440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/1 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]C:\\Users\\colam\\AppData\\Local\\Temp\\ipykernel_30024\\2958784827.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 29/1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:49<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Val Loss = 0.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# üîß Config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üü¢ Using GPU: {torch.cuda.get_device_name(0)}\") if torch.cuda.is_available() else print(\"üü° Using CPU\")\n",
    "\n",
    "batch_size = 4\n",
    "num_classes = 19\n",
    "epochs = 15\n",
    "resize = (256, 512)\n",
    "checkpoint_path = 'deeplabv3_cityscapes_best.pth'\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "\n",
    "# üîÅ Transform con Data Augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(resize),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.3, 0.3, 0.2, 0.1),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(resize),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# üì¶ Dataset & Loader\n",
    "root_dir = 'datasets/realcityscapes'\n",
    "train_ds = CityscapesFineDataset(root=root_dir, split='train', transform=train_transform, resize=resize)\n",
    "val_ds = CityscapesFineDataset(root=root_dir, split='val', transform=val_transform, resize=resize)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# üß† Modello + ottimizzatore + scheduler\n",
    "model = deeplabv3_resnet50(pretrained=False, num_classes=num_classes).to(device)\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.eval()  # evita drifting su batch piccoli\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scaler.load_state_dict(checkpoint['scaler'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "\n",
    "    print(f\"üîÅ Ripreso da epoca {start_epoch}\")\n",
    "else:\n",
    "    print(\"üÜï Nessun checkpoint trovato, si parte da zero.\")\n",
    "\n",
    "# üèÅ Training\n",
    "for epoch in range(start_epoch, start_epoch+epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs+start_epoch} [Train]\")\n",
    "    for images, masks in loop:\n",
    "        images = images.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "        masks = masks.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(images)['out']\n",
    "            loss = criterion(out, masks)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=running_loss/(loop.n+1))\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    print(f\"‚úÖ Epoch {epoch+1}: Avg Train Loss = {avg_train_loss:.4f}\")\n",
    "\n",
    "    # üìâ Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = model(images)['out']\n",
    "                loss = criterion(out, masks)\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    scheduler.step(avg_val_loss)\n",
    "    print(f\"üìâ Avg Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "    # üíæ Salvataggio miglior modello\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scaler': scaler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'best_val_loss': best_val_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "        print(\"üíæ Miglior modello salvato!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd98a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m   \u001b[38;5;66;03m# np.array shape (20, 3)\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# üîß Config\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m device = \u001b[43mtorch\u001b[49m.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33müü¢\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mtorch.cuda.is_available()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33müü°\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Using: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.get_device_name(\u001b[32m0\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mtorch.cuda.is_available()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mCPU\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m num_classes = \u001b[32m19\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "  # np.array shape (20, 3)\n",
    "\n",
    "# üîß Config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"{'üü¢' if torch.cuda.is_available() else 'üü°'} Using: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "num_classes = 19\n",
    "resize = (256, 512)\n",
    "model_path = 'deeplabv3_cityscapes_best.pth'\n",
    "image_path = 'datasets/realcityscapes/leftImg8bit/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png'\n",
    "ground_image_path = 'datasets/realcityscapes/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_color.png'\n",
    "\n",
    "# üîÅ Crea output_dir unico con timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_dir = os.path.join('inference_outputs', f'infer_{timestamp}')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# üß† Load model\n",
    "model = deeplabv3_resnet50(pretrained=False, num_classes=num_classes).to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "\n",
    "# üîÅ Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(resize),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def decode_segmap(pred):\n",
    "    h, w = pred.shape\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for label in range(num_classes):\n",
    "        color_mask[pred == label] = COLORS[label]\n",
    "    return color_mask\n",
    "\n",
    "def run_inference(image_path, ground_path=None):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)['out']\n",
    "        output = torch.nn.functional.interpolate(output, size=resize, mode='bilinear', align_corners=False)\n",
    "\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        confidence, prediction = torch.max(probs, dim=1)\n",
    "\n",
    "        prediction = prediction.squeeze(0).cpu().numpy()\n",
    "        confidence = confidence.squeeze(0).cpu().numpy()\n",
    "\n",
    "        threshold = 0.3\n",
    "        ood_label = 19\n",
    "\n",
    "        prediction_with_ood = prediction.copy()\n",
    "        prediction_with_ood[confidence < threshold] = ood_label\n",
    "\n",
    "        # Assicurati che COLORS abbia 20 colori\n",
    "        seg_image = decode_segmap(prediction_with_ood)\n",
    "\n",
    "\n",
    "    # üì∏ Salvataggio immagini\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    Image.fromarray(seg_image).save(os.path.join(output_dir, f\"{base_name}_pred.png\"))\n",
    "    image.save(os.path.join(output_dir, f\"{base_name}_original.png\"))\n",
    "\n",
    "    if ground_path:\n",
    "        gt = Image.open(ground_path)\n",
    "        gt.save(os.path.join(output_dir, f\"{base_name}_gt.png\"))\n",
    "\n",
    "\n",
    "    from matplotlib import cm\n",
    "    conf_img = (confidence * 255).astype(np.uint8)\n",
    "    Image.fromarray(conf_img).save('confidence_map.png')\n",
    "\n",
    "    plt.imshow(confidence, cmap='hot')\n",
    "    plt.title('Confidence Map')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # üìä Visualizzazione\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(seg_image)\n",
    "    plt.axis('off')\n",
    "\n",
    "    if ground_path:\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.imshow(gt)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{base_name}_all.png\"))\n",
    "    plt.show()\n",
    "\n",
    "# üöÄ Run\n",
    "run_inference(image_path, ground_image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
