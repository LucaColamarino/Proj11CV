{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38aa4aee",
   "metadata": {},
   "source": [
    "# A. Setup e Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bbb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from dataset import BaseSegmentationDataset, build_mapping_array,COLORS\n",
    "from model_uos import DeepLabUOS\n",
    "from conformal_prediction import calibrate_conformal, conformal_mask\n",
    "from train_eval import evaluate_metrics, calculate_mIoU  # Assicurati di avere calculate_mIoU\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"‚úÖ Device:\", device)\n",
    "\n",
    "CITYSCAPES_ROOT = \"datasets/realcityscapes\"\n",
    "LOSTANDFOUND_ROOT = \"datasets/lostandfound\"\n",
    "\n",
    "\n",
    "mapping_array = build_mapping_array(unknown_obstacle_id=7)\n",
    "\n",
    "transform = torch.nn.Sequential()  # usa ToTensor() di default nel dataset\n",
    "\n",
    "train_dataset = BaseSegmentationDataset(\n",
    "    img_dir=os.path.join(CITYSCAPES_ROOT, 'leftImg8bit/train'),\n",
    "    label_dir=os.path.join(CITYSCAPES_ROOT, 'gtFine/train'),\n",
    "    mapping_array=mapping_array,\n",
    "    transform=None,\n",
    "    ood_mode=False\n",
    ")\n",
    "\n",
    "val_dataset = BaseSegmentationDataset(\n",
    "    img_dir=os.path.join(CITYSCAPES_ROOT, 'leftImg8bit/val'),\n",
    "    label_dir=os.path.join(CITYSCAPES_ROOT, 'gtFine/val'),\n",
    "    mapping_array=mapping_array,\n",
    "    transform=None,\n",
    "    ood_mode=False\n",
    ")\n",
    "\n",
    "test_dataset = BaseSegmentationDataset(\n",
    "    img_dir=os.path.join(LOSTANDFOUND_ROOT, 'leftImg8bit/test'),\n",
    "    label_dir=os.path.join(LOSTANDFOUND_ROOT, 'gtCoarse/test'),\n",
    "    mapping_array=mapping_array,\n",
    "    transform=None,\n",
    "    ood_mode=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7257860",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac92eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mask_road_and_obstacles(gt_mask, road_id=1, obstacle_id=4):\n",
    "    \"\"\"\n",
    "    Mantiene solo i pixel di strada e ostacoli, mascherando tutto il resto con -1 (ignored).\n",
    "    Ritorna due mappe:\n",
    "        eval_mask: -1 (ignored), 0 (road), 1 (obstacle)\n",
    "    \"\"\"\n",
    "    eval_mask = np.full_like(gt_mask, -1, dtype=np.int8)  # tutto ignorato di default\n",
    "\n",
    "    # Strada = 0 (negativo)\n",
    "    eval_mask[gt_mask == road_id] = 0\n",
    "\n",
    "    # Ostacolo = 1 (positivo OoD)\n",
    "    eval_mask[gt_mask == obstacle_id] = 1\n",
    "\n",
    "    return eval_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_exclude_giant(gt_mask, max_exclude=80000):\n",
    "    \"\"\"\n",
    "    Mantiene tutti i blob OoD tranne quelli giganti (area > max_exclude)\n",
    "    \"\"\"\n",
    "    filtered = np.copy(gt_mask)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(gt_mask, connectivity=8)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] > max_exclude:\n",
    "            filtered[labels == i] = 0\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_with_ood(img, pred_classes, pred_mask_ood, title=\"Prediction with OoD Highlight\"):\n",
    "    \"\"\"\n",
    "    img: torch.Tensor [C,H,W] immagine di input\n",
    "    pred_classes: np.array [H,W] -> classi predette (0..7)\n",
    "    pred_mask_ood: np.array [H,W] binaria (1 = OoD / ostacolo)\n",
    "    \"\"\"\n",
    "    # ‚úÖ Prepara immagine e prediction colorata\n",
    "    img_np = img.permute(1, 2, 0).cpu().numpy()\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "    pred_color = decode_segmap(pred_classes)\n",
    "\n",
    "    # ‚úÖ Overlay rosso sugli OoD\n",
    "    overlay = pred_color.copy()\n",
    "    overlay[pred_mask_ood == 1] = (255, 0, 0)  # rosso per gli ostacoli\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Input\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f79ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_segmap(mask):\n",
    "    \"\"\"Converte una mask [H,W] di classi in immagine RGB colorata.\"\"\"\n",
    "    h, w = mask.shape\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for cls_id, color in enumerate(COLORS):\n",
    "        color_mask[mask == cls_id] = color\n",
    "    return color_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959099d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_model_prediction(img, pred_mask, title=\"Model Prediction\"):\n",
    "    \"\"\"\n",
    "    img: torch.Tensor [C,H,W]\n",
    "    pred_mask: np.array [H,W] con classi (0..7)\n",
    "    \"\"\"\n",
    "    img_np = img.permute(1, 2, 0).cpu().numpy()\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())  # Normalizza [0,1]\n",
    "    pred_color = decode_segmap(pred_mask)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Input\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(pred_color)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_full_paper_style(img, gt_multi, gt_ood_filtered, pred_ood, title=\"OoD Detection\"):\n",
    "    img_np = (img.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "    gt_color = decode_segmap(gt_multi)\n",
    "\n",
    "    overlay = np.copy(img_np)\n",
    "    tp = (gt_ood_filtered == 1) & (pred_ood == 1)\n",
    "    fp = (gt_ood_filtered == 0) & (pred_ood == 1)\n",
    "    fn = (gt_ood_filtered == 1) & (pred_ood == 0)\n",
    "    overlay[tp] = [0, 255, 0]\n",
    "    overlay[fp] = [255, 0, 0]\n",
    "    overlay[fn] = [0, 0, 255]\n",
    "    blended = cv2.addWeighted(img_np, 0.5, overlay, 0.5, 0)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 4, 1); plt.imshow(img_np); plt.title(\"Input\"); plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 2); plt.imshow(gt_color); plt.title(\"GT Multi-class\"); plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 3); plt.imshow(gt_ood_filtered, cmap=\"gray\"); plt.title(\"GT OoD (Filtered)\"); plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 4); plt.imshow(blended); plt.title(\"TP(G)/FP(R)/FN(B)\"); plt.axis(\"off\")\n",
    "    plt.suptitle(title); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_only_small_ood(gt_mask, max_size=20000):\n",
    "    filtered = np.zeros_like(gt_mask, dtype=np.uint8)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(gt_mask, connectivity=8)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] <= max_size:\n",
    "            filtered[labels == i] = 1\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34585b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            out = model(imgs)\n",
    "            logits = out[\"logits\"]\n",
    "            loss = criterion(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23548cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_full_paper_style(img, gt_multi, gt_ood_filtered, pred_ood, title=\"OoD Detection (Small Obstacles Only)\"):\n",
    "    \"\"\"\n",
    "    img: torch.Tensor [C,H,W], valori [0,1]\n",
    "    gt_multi: np.array [H,W], valori macro-classi (0..7)\n",
    "    gt_ood_filtered: np.array [H,W], 0/1 (solo piccoli ostacoli)\n",
    "    pred_ood: np.array [H,W], 0/1 (OoD prediction)\n",
    "    \"\"\"\n",
    "    # ---- 1. Input Image ----\n",
    "    img_np = (img.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    # ---- 2. GT Multi-class Colorata ----\n",
    "    gt_color = decode_segmap(gt_multi)\n",
    "\n",
    "    # ---- 3. Confusion Overlay ----\n",
    "    overlay = np.copy(img_np)\n",
    "    tp = (gt_ood_filtered == 1) & (pred_ood == 1)\n",
    "    fp = (gt_ood_filtered == 0) & (pred_ood == 1)\n",
    "    fn = (gt_ood_filtered == 1) & (pred_ood == 0)\n",
    "\n",
    "    overlay[tp] = [0, 255, 0]    # Verde = TP\n",
    "    overlay[fp] = [255, 0, 0]    # Rosso = FP\n",
    "    overlay[fn] = [0, 0, 255]    # Blu = FN\n",
    "\n",
    "    blended = cv2.addWeighted(img_np, 0.5, overlay, 0.5, 0)\n",
    "\n",
    "    # ---- 4. Plot a 4 riquadri ----\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Input\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(gt_color)\n",
    "    plt.title(\"GT Multi-class\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(gt_ood_filtered, cmap=\"gray\")\n",
    "    plt.title(\"GT OoD (Small Obstacles)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(blended)\n",
    "    plt.title(\"Overlay TP(G)/FP(R)/FN(B)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_small_ood(gt_mask, max_size=5000):\n",
    "    \"\"\"\n",
    "    gt_mask: np.array [H,W], valori 0/1 (OoD binario)\n",
    "    max_size: max pixel per considerare un blob come ostacolo\n",
    "    \"\"\"\n",
    "    filtered = np.zeros_like(gt_mask, dtype=np.uint8)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(gt_mask.astype(np.uint8), connectivity=8)\n",
    "    \n",
    "    for i in range(1, num_labels):  # 0 = background\n",
    "        if stats[i, cv2.CC_STAT_AREA] <= max_size:\n",
    "            filtered[labels == i] = 1\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_pr(all_scores, all_gts, title_suffix=\"(OoD Small Obstacles)\"):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # ROC\n",
    "    plt.subplot(1, 2, 1)\n",
    "    RocCurveDisplay.from_predictions(all_gts, all_scores)\n",
    "    plt.title(f\"ROC Curve {title_suffix}\")\n",
    "\n",
    "    # PR Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    PrecisionRecallDisplay.from_predictions(all_gts, all_scores)\n",
    "    plt.title(f\"Precision-Recall Curve {title_suffix}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba2adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tavolozza macro-classi (uguale al dataset)\n",
    "COLORS = np.array([\n",
    "    (128, 64, 128),   # 0 - Road\n",
    "    (244, 35, 232),   # 1 - Flat\n",
    "    (220, 20, 60),    # 2 - Human\n",
    "    (0, 0, 142),      # 3 - Vehicle\n",
    "    (153, 153, 153),  # 4 - Construction\n",
    "    (250, 170, 30),   # 5 - Objects\n",
    "    (107, 142, 35),   # 6 - Vegetation\n",
    "    (255, 255, 255),  # 7 - OoD (Unknown)\n",
    "], dtype=np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fcc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_comparison(img, gt_multi, gt_ood, pred_ood, title=\"OoD Detection\"):\n",
    "    # ‚úÖ L'immagine √® gi√† in [0,1], non serve de-normalizzare\n",
    "    img_np = img.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    gt_color = decode_segmap(gt_multi)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Input\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(gt_color)\n",
    "    plt.title(\"GT Multi-class\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(gt_ood, cmap=\"gray\")\n",
    "    plt.title(\"GT OoD\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(pred_ood, cmap=\"gray\")\n",
    "    plt.title(\"Prediction OoD\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_overlay(img, gt_ood, pred_ood, title=\"OoD Confusion Overlay\"):\n",
    "    \"\"\"\n",
    "    img: torch.Tensor [C,H,W] (0-1)\n",
    "    gt_ood: np.array [H,W] (0/1)\n",
    "    pred_ood: np.array [H,W] (0/1)\n",
    "    \"\"\"\n",
    "    img_np = (img.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    # TP=verde, FP=rosso, FN=blu\n",
    "    overlay = np.copy(img_np)\n",
    "    tp = (gt_ood == 1) & (pred_ood == 1)\n",
    "    fp = (gt_ood == 0) & (pred_ood == 1)\n",
    "    fn = (gt_ood == 1) & (pred_ood == 0)\n",
    "\n",
    "    overlay[tp] = [0, 255, 0]    # Verde\n",
    "    overlay[fp] = [255, 0, 0]    # Rosso\n",
    "    overlay[fn] = [0, 0, 255]    # Blu\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cv2.addWeighted(img_np, 0.5, overlay, 0.5, 0))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64530f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "def plot_roc_pr(all_scores, all_gts):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    RocCurveDisplay.from_predictions(all_gts, all_scores)\n",
    "    plt.title(\"ROC Curve (OoD)\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    PrecisionRecallDisplay.from_predictions(all_gts, all_scores)\n",
    "    plt.title(\"Precision-Recall Curve (OoD)\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a614d4c0",
   "metadata": {},
   "source": [
    "# B. Modello + Training (Poly LR + Best mIoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 7\n",
    "model = DeepLabUOS(n_classes=n_classes, normalize_uos=True).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "MODEL_PATH = \"deeplab_uos_trained.pth\"\n",
    "EPOCHS = 3\n",
    "start_epoch = 0\n",
    "best_mIoU = 0.0\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    if \"optimizer_state\" in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    start_epoch = checkpoint.get(\"epoch\", -1) + 1\n",
    "    best_mIoU = checkpoint.get(\"mIoU\", 0.0)\n",
    "    print(f\"‚úÖ Riprendo da Epoch {start_epoch} (Best mIoU {best_mIoU:.4f})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nessun modello trovato, training da zero.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23106761",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_iter = (EPOCHS + start_epoch) * len(train_loader)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda it: (1 - it / max_iter) ** 0.9)\n",
    "\n",
    "train_losses, val_mious = [], []\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS + start_epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS+start_epoch}\", leave=False)\n",
    "\n",
    "    for imgs, labels in progress_bar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        logits = out[\"logits\"]\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"loss\": f\"{epoch_loss / (progress_bar.n + 1):.4f}\"})\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    val_mIoU = calculate_mIoU(model, val_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    val_mious.append(val_mIoU)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS+start_epoch} - Train Loss: {avg_loss:.4f} | Val mIoU: {val_mIoU:.4f}\")\n",
    "\n",
    "    if val_mIoU > best_mIoU:\n",
    "        best_mIoU = val_mIoU\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"mIoU\": best_mIoU\n",
    "        }, MODEL_PATH)\n",
    "        print(f\"‚úÖ Miglior modello aggiornato (Val mIoU: {best_mIoU:.4f})\")\n",
    "\n",
    "print(f\"üèÅ Training completato! Best Val mIoU finale: {best_mIoU:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f87387",
   "metadata": {},
   "source": [
    "# C. Testing con filtro ostacoli grandi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Calibrazione conformale ----\n",
    "calib_scores = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, _ in val_loader:\n",
    "        uos = model(imgs.to(device))[\"uos\"]\n",
    "        calib_scores.append(uos.cpu().numpy())\n",
    "\n",
    "calib_scores = np.concatenate(calib_scores).flatten()\n",
    "alpha = 0.1  # Soglia di confidenza per la calibrazione\n",
    "qhat = calibrate_conformal(calib_scores, alpha=alpha)\n",
    "print(f\"‚úÖ Conformal threshold qÃÇ: {qhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Testing ----\n",
    "all_scores, all_gts = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        out = model(imgs.to(device))\n",
    "        uos = out[\"uos\"].cpu().numpy()\n",
    "\n",
    "        # ‚úÖ Smoothing spaziale (applicato per ogni immagine nel batch)\n",
    "        for i in range(uos.shape[0]):\n",
    "            # üîπ Smoothing\n",
    "            uos[i, 0] = cv2.GaussianBlur(uos[i, 0], (5, 5), 0)\n",
    "\n",
    "            # üîπ GT road+obstacles masking (LostAndFound evaluation)\n",
    "            gt_eval = mask_road_and_obstacles(labels[i].numpy(), road_id=1, obstacle_id=4)\n",
    "            \n",
    "            # üîπ Filtro opzionale (grandi blob)\n",
    "            gt_mask = (labels[i].numpy() == 4).astype(np.uint8)\n",
    "            gt_mask_filtered = filter_exclude_giant(gt_mask, max_exclude=120000)\n",
    "\n",
    "            # üîπ Validi solo strada + ostacoli\n",
    "            valid_pixels = gt_eval != -1\n",
    "\n",
    "            # üîπ Aggiungi i valori validi\n",
    "            uos_map = uos[i, 0]  # [H, W]\n",
    "            all_scores.append(uos_map[valid_pixels])\n",
    "            all_gts.append(gt_eval[valid_pixels])\n",
    "\n",
    "\n",
    "\n",
    "all_scores = np.concatenate(all_scores).flatten()\n",
    "all_gts = np.concatenate(all_gts).flatten()\n",
    "\n",
    "print(\"OoD pixel count (filtered):\", np.sum(all_gts))\n",
    "metrics = evaluate_metrics(all_scores, all_gts)\n",
    "print(f\"AUROC: {metrics['AUROC']:.4f} | AP: {metrics['AP']:.4f} | FPR95: {metrics['FPR95']:.4f}\")\n",
    "\n",
    "\n",
    "print(\"OoD pixel count:\", np.sum(all_gts))\n",
    "print(\"Scores range:\", all_scores.min(), all_scores.max())\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ood_scores = all_scores[all_gts == 1]\n",
    "ind_scores = all_scores[all_gts == 0]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.kdeplot(ind_scores, label=\"In-Distribution\", fill=True, alpha=0.5)\n",
    "sns.kdeplot(ood_scores, label=\"OoD\", fill=True, alpha=0.5)\n",
    "plt.title(\"Distribuzione UOS OoD vs In-Distribution\")\n",
    "plt.xlabel(\"UOS score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf8be6",
   "metadata": {},
   "source": [
    "# D. Visualizzazioni (Paper Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64adb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for idx, (imgs, labels) in enumerate(test_loader):\n",
    "        if idx < 16:\n",
    "            continue\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        out = model(imgs)\n",
    "\n",
    "        objectness = out[\"objectness\"].cpu().numpy()\n",
    "        us = out[\"us\"].cpu().numpy()\n",
    "        uos = out[\"uos\"].cpu().numpy()\n",
    "\n",
    "        obj_map = objectness[0, 0]\n",
    "        us_map = us[0, 0]\n",
    "        uos_map = uos[0, 0]\n",
    "        uos_map = cv2.GaussianBlur(uos_map, (5, 5), 0)\n",
    "\n",
    "        # ‚úÖ Conformal threshold\n",
    "        pred_mask = (uos_map > qhat).astype(np.uint8)\n",
    "\n",
    "        # ‚úÖ Maschera GT: solo strada + ostacoli (LostAndFound protocol)\n",
    "        lbl_np = labels.squeeze(0).numpy()\n",
    "        gt_eval = mask_road_and_obstacles(lbl_np, road_id=1, obstacle_id=4)\n",
    "        valid_pixels = gt_eval != -1\n",
    "\n",
    "        # ‚úÖ Maschera OoD solo su pixel validi\n",
    "        gt_mask_ood = (gt_eval == 1).astype(np.uint8)\n",
    "\n",
    "        # ‚úÖ Plot predizione classi\n",
    "        pred_mask_c = out[\"logits\"].argmax(dim=1).squeeze(0).cpu().numpy()\n",
    "        plot_model_prediction(imgs[0], pred_mask_c, title=\"Prediction (All Classes)\")\n",
    "\n",
    "        # ‚úÖ Plot predizione OoD (solo sui pixel validi)\n",
    "        plot_prediction_with_ood(imgs[0], pred_mask_c, pred_mask * valid_pixels,\n",
    "                                 title=\"Prediction (OoD in Red, masked)\")\n",
    "\n",
    "        plot_full_paper_style(imgs[0], lbl_np, gt_mask_ood, pred_mask * valid_pixels,\n",
    "                              title=f\"Sample {idx}\")\n",
    "        break\n",
    "\n",
    "\n",
    "# Copie delle mappe originali\n",
    "obj_map_masked = obj_map.copy()\n",
    "us_map_masked = us_map.copy()\n",
    "uos_map_masked = uos_map.copy()\n",
    "\n",
    "# Imposta a 0 i pixel fuori dai valid_pixels (invece che np.nan)\n",
    "obj_map_masked[~valid_pixels] = 0.0\n",
    "us_map_masked[~valid_pixels] = 0.0\n",
    "uos_map_masked[~valid_pixels] = 0.0\n",
    "\n",
    "# ‚úÖ Plot\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(obj_map_masked, cmap=\"viridis\")\n",
    "plt.title(\"Objectness (masked, full image)\")\n",
    "plt.colorbar(); plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(us_map_masked, cmap=\"magma\")\n",
    "plt.title(\"US (masked, full image)\")\n",
    "plt.colorbar(); plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(uos_map_masked, cmap=\"plasma\")\n",
    "plt.title(\"UOS (masked, full image)\")\n",
    "plt.colorbar(); plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Objectness vs US vs UOS (full image, masked=0)\", fontsize=14)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
